
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../preprocess/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.24">
    
    
      
        <title>Building a Model - WeThePeople</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tensorflow-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="WeThePeople" class="md-header__button md-logo" aria-label="WeThePeople" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            WeThePeople
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Building a Model
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="WeThePeople" class="md-nav__button md-logo" aria-label="WeThePeople" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    WeThePeople
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Sourcing Datasets
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Sourcing Datasets
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../get_all_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../congress_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Congress.gov Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fred_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FRED Data
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../preprocess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Building a Model
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Building a Model
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensorflow-models" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel1" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomModel1
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomModel1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel1.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel1.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-model-layers" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow model layers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention" class="md-nav__link">
    <span class="md-ellipsis">
      BaseAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BaseAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention.build" class="md-nav__link">
    <span class="md-ellipsis">
      build
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BertEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      BertEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BertEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BertEncoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BertEncoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.DistilBertEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      DistilBertEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DistilBertEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.DistilBertEncoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.DistilBertEncoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN" class="md-nav__link">
    <span class="md-ellipsis">
      FeedForwardNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FeedForwardNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      MyBertTokenizer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyBertTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizer.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizerTrimmed" class="md-nav__link">
    <span class="md-ellipsis">
      MyBertTokenizerTrimmed
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyBertTokenizerTrimmed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizerTrimmed.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizerTrimmed.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoderLayer" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomDecoderLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomDecoderLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoderLayer.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoderLayer.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomSimpleDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomSimpleDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomSimpleDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomSimpleDecoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomSimpleDecoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      PositionalEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCausalSelfAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SimpleCausalSelfAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimpleCausalSelfAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCausalSelfAttention.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCrossAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SimpleCrossAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimpleCrossAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCrossAttention.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleSelfAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SimpleSelfAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimpleSelfAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleSelfAttention.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensorflow-models" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel1" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomModel1
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomModel1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel1.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_models.MyCustomModel1.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-model-layers" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow model layers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention" class="md-nav__link">
    <span class="md-ellipsis">
      BaseAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BaseAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention.build" class="md-nav__link">
    <span class="md-ellipsis">
      build
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BaseAttention.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BertEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      BertEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BertEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BertEncoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.BertEncoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.DistilBertEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      DistilBertEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DistilBertEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.DistilBertEncoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.DistilBertEncoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN" class="md-nav__link">
    <span class="md-ellipsis">
      FeedForwardNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FeedForwardNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.FeedForwardNN.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      MyBertTokenizer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyBertTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizer.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizerTrimmed" class="md-nav__link">
    <span class="md-ellipsis">
      MyBertTokenizerTrimmed
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyBertTokenizerTrimmed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizerTrimmed.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyBertTokenizerTrimmed.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoderLayer" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomDecoderLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomDecoderLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoderLayer.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomDecoderLayer.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomSimpleDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      MyCustomSimpleDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MyCustomSimpleDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomSimpleDecoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.MyCustomSimpleDecoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      PositionalEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.PositionalEncoder.get_config" class="md-nav__link">
    <span class="md-ellipsis">
      get_config
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCausalSelfAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SimpleCausalSelfAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimpleCausalSelfAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCausalSelfAttention.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCrossAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SimpleCrossAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimpleCrossAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleCrossAttention.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleSelfAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SimpleSelfAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimpleSelfAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.modeling.models.custom_layers.SimpleSelfAttention.call" class="md-nav__link">
    <span class="md-ellipsis">
      call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Building a Model</h1>

<h2 id="tensorflow-models">TensorFlow models</h2>


<div class="doc doc-object doc-module">




    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_models.MyCustomModel" class="doc doc-heading">
            <code>MyCustomModel</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.Model">Model</span></code></p>


      <p>Encoder-Decoder Transformer that predicts numerical time-series based on text input.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>decoder_stack_height</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decoder blocks in decoder</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>d_model</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic vector length used for configuring attention layers.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>h_model</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads for all Multi Head Attention blocks in the decoder stack.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder_dropout_rate</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic dropout rate used across decoder stack.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_decoder_vocab</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of entries in decoder (numerical) vocabulary.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>label_seq_length</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of time-series ultimately predicted by decoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>encoder_max_seq_len</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length to which the encoder trims tokenized text sequences.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vocab_file</code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Location of vocab file in filesystem.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_models.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyCustomModel</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encoder-Decoder Transformer that predicts numerical time-series based on text input.</span>

<span class="sd">    Args:</span>
<span class="sd">        decoder_stack_height (int): Number of decoder blocks in decoder</span>
<span class="sd">        d_model (int): Characteristic vector length used for configuring attention layers.</span>
<span class="sd">        h_model (int): Number of heads for all Multi Head Attention blocks in the decoder stack.</span>
<span class="sd">        decoder_dropout_rate (float): Characteristic dropout rate used across decoder stack.</span>
<span class="sd">        n_decoder_vocab (int): Number of entries in decoder (numerical) vocabulary.</span>
<span class="sd">        label_seq_length (int): Length of time-series ultimately predicted by decoder.</span>
<span class="sd">        encoder_max_seq_len (int): Length to which the encoder trims tokenized text sequences.</span>
<span class="sd">        vocab_file (_type_): Location of vocab file in filesystem.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">decoder_stack_height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">decoder_dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">n_decoder_vocab</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">label_seq_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">encoder_max_seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span> <span class="o">=</span> <span class="n">decoder_stack_height</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span> <span class="o">=</span> <span class="n">h_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span> <span class="o">=</span> <span class="n">decoder_dropout_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span> <span class="o">=</span> <span class="n">n_decoder_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span> <span class="o">=</span> <span class="n">label_seq_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span> <span class="o">=</span> <span class="n">encoder_max_seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span> <span class="o">=</span> <span class="n">vocab_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">DistilBertEncoder</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">MyCustomSimpleDecoder</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">bill_text</span><span class="p">,</span> <span class="n">prebill_series</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">bill_text</span><span class="p">)</span>
        <span class="n">dec_inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
            <span class="n">prebill_series</span>
        <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1], decoder input</span>
        <span class="c1"># not efficient cuz context vectors recomputed every time</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span><span class="p">(</span>
                <span class="n">dec_inp</span>
            <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            <span class="n">new_token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Get last item</span>
            <span class="n">dec_inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dec_inp</span><span class="p">,</span> <span class="n">new_token_emb</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;decoder_stack_height &quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span><span class="p">,</span>
                <span class="s2">&quot;d_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
                <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="s2">&quot;decoder_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span><span class="p">,</span>
                <span class="s2">&quot;n_decoder_vocab&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span><span class="p">,</span>
                <span class="s2">&quot;label_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span><span class="p">,</span>
                <span class="s2">&quot;encoder_max_seq_len&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span><span class="p">,</span>
                <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_models.MyCustomModel.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_models.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">bill_text</span><span class="p">,</span> <span class="n">prebill_series</span> <span class="o">=</span> <span class="nb">input</span>
    <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">bill_text</span><span class="p">)</span>
    <span class="n">dec_inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
        <span class="n">prebill_series</span>
    <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1], decoder input</span>
    <span class="c1"># not efficient cuz context vectors recomputed every time</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span><span class="p">(</span>
            <span class="n">dec_inp</span>
        <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">new_token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Get last item</span>
        <span class="n">dec_inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dec_inp</span><span class="p">,</span> <span class="n">new_token_emb</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_models.MyCustomModel.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_models.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;decoder_stack_height &quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span><span class="p">,</span>
            <span class="s2">&quot;d_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
            <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
            <span class="s2">&quot;decoder_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span><span class="p">,</span>
            <span class="s2">&quot;n_decoder_vocab&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span><span class="p">,</span>
            <span class="s2">&quot;label_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span><span class="p">,</span>
            <span class="s2">&quot;encoder_max_seq_len&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span><span class="p">,</span>
            <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_models.MyCustomModel1" class="doc doc-heading">
            <code>MyCustomModel1</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.Model">Model</span></code></p>


      <p>Encoder-Decoder Transformer that predicts numerical time-series based on text input.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>decoder_stack_height</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decoder blocks in decoder</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>d_keys</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of key vectors in all attention layers except within BERT pretrained layer.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>d_values</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of value vectors in all attention layers except within BERT pretrained layer.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>h_model</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads for all Multi Head Attention blocks in the decoder stack.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder_dropout_rate</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic dropout rate used across decoder stack.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_decoder_vocab</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of entries in decoder (numerical) vocabulary.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>label_seq_length</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of time-series ultimately predicted by decoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>encoder_max_seq_len</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length to which the encoder trims tokenized text sequences.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vocab_file</code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Location of vocab file in filesystem.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_models.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyCustomModel1</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encoder-Decoder Transformer that predicts numerical time-series based on text input.</span>

<span class="sd">    Args:</span>
<span class="sd">        decoder_stack_height (int): Number of decoder blocks in decoder</span>
<span class="sd">        d_keys (int): Length of key vectors in all attention layers except within BERT pretrained layer.</span>
<span class="sd">        d_values (int): Length of value vectors in all attention layers except within BERT pretrained layer.</span>
<span class="sd">        h_model (int): Number of heads for all Multi Head Attention blocks in the decoder stack.</span>
<span class="sd">        decoder_dropout_rate (float): Characteristic dropout rate used across decoder stack.</span>
<span class="sd">        n_decoder_vocab (int): Number of entries in decoder (numerical) vocabulary.</span>
<span class="sd">        label_seq_length (int): Length of time-series ultimately predicted by decoder.</span>
<span class="sd">        encoder_max_seq_len (int): Length to which the encoder trims tokenized text sequences.</span>
<span class="sd">        vocab_file (_type_): Location of vocab file in filesystem.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">decoder_stack_height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">d_keys</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">d_values</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">decoder_dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">n_decoder_vocab</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">label_seq_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">encoder_max_seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span> <span class="o">=</span> <span class="n">decoder_stack_height</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span> <span class="o">=</span> <span class="n">d_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span> <span class="o">=</span> <span class="n">d_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span> <span class="o">=</span> <span class="n">h_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span> <span class="o">=</span> <span class="n">decoder_dropout_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span> <span class="o">=</span> <span class="n">n_decoder_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span> <span class="o">=</span> <span class="n">label_seq_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span> <span class="o">=</span> <span class="n">encoder_max_seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span> <span class="o">=</span> <span class="n">vocab_file</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">DistilBertEncoder</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">MyCustomDecoder</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">bill_text</span><span class="p">,</span> <span class="n">prebill_series</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">bill_text</span><span class="p">)</span>
        <span class="n">dec_inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
            <span class="n">prebill_series</span>
        <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1], decoder input</span>
        <span class="c1"># not efficient cuz context vectors recomputed every time</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span><span class="p">(</span>
                <span class="n">dec_inp</span>
            <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            <span class="n">new_token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Get last item</span>
            <span class="n">dec_inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dec_inp</span><span class="p">,</span> <span class="n">new_token_emb</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;decoder_stack_height &quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span><span class="p">,</span>
                <span class="s2">&quot;d_keys&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
                <span class="s2">&quot;d_values&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
                <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="s2">&quot;decoder_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span><span class="p">,</span>
                <span class="s2">&quot;n_decoder_vocab&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span><span class="p">,</span>
                <span class="s2">&quot;label_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span><span class="p">,</span>
                <span class="s2">&quot;encoder_max_seq_len&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span><span class="p">,</span>
                <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_models.MyCustomModel1.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_models.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">bill_text</span><span class="p">,</span> <span class="n">prebill_series</span> <span class="o">=</span> <span class="nb">input</span>
    <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">bill_text</span><span class="p">)</span>
    <span class="n">dec_inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
        <span class="n">prebill_series</span>
    <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1], decoder input</span>
    <span class="c1"># not efficient cuz context vectors recomputed every time</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span><span class="p">(</span>
            <span class="n">dec_inp</span>
        <span class="p">)</span>  <span class="c1"># Output shape: [batch, Ty, dv1]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">new_token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Get last item</span>
        <span class="n">dec_inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dec_inp</span><span class="p">,</span> <span class="n">new_token_emb</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">dec_inp</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">output_seq_length</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_models.MyCustomModel1.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_models.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;decoder_stack_height &quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_stack_height</span><span class="p">,</span>
            <span class="s2">&quot;d_keys&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
            <span class="s2">&quot;d_values&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
            <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
            <span class="s2">&quot;decoder_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dropout_rate</span><span class="p">,</span>
            <span class="s2">&quot;n_decoder_vocab&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_decoder_vocab</span><span class="p">,</span>
            <span class="s2">&quot;label_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_seq_length</span><span class="p">,</span>
            <span class="s2">&quot;encoder_max_seq_len&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_max_seq_len</span><span class="p">,</span>
            <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><h2 id="tensorflow-model-layers">TensorFlow model layers</h2>


<div class="doc doc-object doc-module">




    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.BaseAttention" class="doc doc-heading">
            <code>BaseAttention</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Base class for attention block, consisting of add, norm, and multihead attention layers.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.num_heads">num_heads</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads in Multi Head Attention.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.key_dim">key_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the key tensor.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.value_dim">value_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the value tensor.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.dropout_rate">dropout_rate</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout rate in Multi Head Attention.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.add">add</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Adding layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.norm">norm</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Normalizing layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BaseAttention.mha">mha</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Multi Head Attention layer.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseAttention</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for attention block, consisting of add, norm, and multihead attention layers.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        num_heads (int): Number of heads in Multi Head Attention.</span>
<span class="sd">        key_dim (int): Length of the key tensor.</span>
<span class="sd">        value_dim (int): Length of the value tensor.</span>
<span class="sd">        dropout_rate (float): Dropout rate in Multi Head Attention.</span>
<span class="sd">        add (tf.keras.layers.Layer): Adding layer.</span>
<span class="sd">        norm (tf.keras.layers.Layer): Normalizing layer.</span>
<span class="sd">        mha (tf.keras.layers.Layer): Multi Head Attention layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">key_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">value_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes instance based on desired attributes.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key_dim</span> <span class="o">=</span> <span class="n">key_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_dim</span> <span class="o">=</span> <span class="n">value_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">key_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span>
        <span class="p">)</span>

    <span class="c1"># add a build function for mha (per docs)?</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Not sure if this is necessary in all honesty.&quot;&quot;&quot;</span>
        <span class="c1"># super().build()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="o">.</span><span class="n">_build_from_signature</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;num_heads&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
                <span class="s2">&quot;key_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">key_dim</span><span class="p">,</span>
                <span class="s2">&quot;value_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_dim</span><span class="p">,</span>
                <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.BaseAttention.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">key_dim</span><span class="p">,</span> <span class="n">value_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes instance based on desired attributes.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">key_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">value_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes instance based on desired attributes.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">key_dim</span> <span class="o">=</span> <span class="n">key_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">value_dim</span> <span class="o">=</span> <span class="n">value_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">key_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.BaseAttention.build" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">build</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Not sure if this is necessary in all honesty.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Not sure if this is necessary in all honesty.&quot;&quot;&quot;</span>
    <span class="c1"># super().build()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="o">.</span><span class="n">_build_from_signature</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.BaseAttention.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;num_heads&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
            <span class="s2">&quot;key_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">key_dim</span><span class="p">,</span>
            <span class="s2">&quot;value_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_dim</span><span class="p">,</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.BertEncoder" class="doc doc-heading">
            <code>BertEncoder</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Encoder based on Google's BERT model.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BertEncoder.projection_dim">projection_dim</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of final hidden state vector output by encoder.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BertEncoder.max_seq_length">max_seq_length</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length to which tokenized sequences are trimmed.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BertEncoder.tokenizer">tokenizer</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>choice of tokenizer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BertEncoder.bert">bert</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Pretrained BERT model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.BertEncoder.broadcaster">broadcaster</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dense layer that broadcasts output of pretrained BERT model into <code>projection_dim</code> dimensionality.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BertEncoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encoder based on Google&#39;s BERT model.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        projection_dim (_type_): Length of final hidden state vector output by encoder.</span>
<span class="sd">        max_seq_length (_type_): Length to which tokenized sequences are trimmed.</span>
<span class="sd">        tokenizer (_type_): choice of tokenizer.</span>
<span class="sd">        bert (_type_): Pretrained BERT model.</span>
<span class="sd">        broadcaster (_type_): Dense layer that broadcasts output of pretrained BERT model into `projection_dim` dimensionality.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MyBertTokenizer</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">TFBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">,</span>
                <span class="n">max_position_embeddings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">TFBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># freeze pre-trained weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcaster</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">broadcaster</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">pooler_output</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;projection_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span>
                <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.BertEncoder.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">broadcaster</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">pooler_output</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.BertEncoder.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;projection_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span>
            <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.DistilBertEncoder" class="doc doc-heading">
            <code>DistilBertEncoder</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Encoder based on Google's DistilBERT model.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.DistilBertEncoder.projection_dim">projection_dim</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of final hidden state vector output by encoder.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.DistilBertEncoder.max_seq_length">max_seq_length</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length to which tokenized sequences are trimmed.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.DistilBertEncoder.vocab_file">vocab_file</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Location of vocab file in filesystem.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.DistilBertEncoder.tokenizer">tokenizer</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>choice of tokenizer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.DistilBertEncoder.bert">bert</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Pretrained DistilBERT model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.DistilBertEncoder.broadcaster">broadcaster</span></code></td>
            <td>
                  <code>_type_</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dense layer that broadcasts output of pretrained BERT model into <code>projection_dim</code> dimensionality.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DistilBertEncoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encoder based on Google&#39;s DistilBERT model.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        projection_dim (_type_): Length of final hidden state vector output by encoder.</span>
<span class="sd">        max_seq_length (_type_): Length to which tokenized sequences are trimmed.</span>
<span class="sd">        vocab_file (_type_): Location of vocab file in filesystem.</span>
<span class="sd">        tokenizer (_type_): choice of tokenizer.</span>
<span class="sd">        bert (_type_): Pretrained DistilBERT model.</span>
<span class="sd">        broadcaster (_type_): Dense layer that broadcasts output of pretrained BERT model into `projection_dim` dimensionality.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span> <span class="o">=</span> <span class="n">vocab_file</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MyBertTokenizerTrimmed</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">TFDistilBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span><span class="p">,</span>
                <span class="n">max_position_embeddings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MyBertTokenizer</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">TFDistilBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># freeze pre-trained weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcaster</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">x</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;token_type_ids&quot;</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcaster</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;projection_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span>
                <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span>
                <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.DistilBertEncoder.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">x</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;token_type_ids&quot;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcaster</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.DistilBertEncoder.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;projection_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span>
            <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span>
            <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.FeedForwardNN" class="doc doc-heading">
            <code>FeedForwardNN</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Feed Forward Neural Network block consisting of a densely connected NN with ReLU activation, a densely connected NN with no activation, a dropout layer, an add layer, and a normalization layer.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.output_dim">output_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of output vector of both Dense layers.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.ff_dropout_rate">ff_dropout_rate</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout rate used in dropout layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.relu">relu</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dense layer, ReLU activation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.linear">linear</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dense layer, no activation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.dropout">dropout</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.add">add</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Add layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.FeedForwardNN.norm">norm</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Layer normalization layer.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">FeedForwardNN</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Feed Forward Neural Network block consisting of a densely connected NN with ReLU activation, a densely connected NN with no activation, a dropout layer, an add layer, and a normalization layer.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        output_dim (int): Length of output vector of both Dense layers.</span>
<span class="sd">        ff_dropout_rate (float): Dropout rate used in dropout layer.</span>
<span class="sd">        relu (tf.keras.layers.Layer): Dense layer, ReLU activation.</span>
<span class="sd">        linear (tf.keras.layers.Layer): Dense layer, no activation.</span>
<span class="sd">        dropout (tf.keras.layers.Layer): Dropout layer.</span>
<span class="sd">        add (tf.keras.layers.Layer): Add layer.</span>
<span class="sd">        norm (tf.keras.layers.Layer): Layer normalization layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ff_dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize instance based on desired output dimension and dropout rate.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span> <span class="o">=</span> <span class="n">ff_dropout_rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="s2">&quot;ff_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.FeedForwardNN.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">ff_dropout_rate</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initialize instance based on desired output dimension and dropout rate.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ff_dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize instance based on desired output dimension and dropout rate.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span> <span class="o">=</span> <span class="n">ff_dropout_rate</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.FeedForwardNN.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.FeedForwardNN.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="s2">&quot;ff_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.MyBertTokenizer" class="doc doc-heading">
            <code>MyBertTokenizer</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>BERT Tokenizer.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyBertTokenizer.vocab_file">vocab_file</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Location of BERT vocabulary in filesystem.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyBertTokenizer</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;BERT Tokenizer.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        vocab_file (str): Location of BERT vocabulary in filesystem.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">START_TOKEN</span> <span class="o">=</span> <span class="mi">101</span>
    <span class="n">END_TOKEN</span> <span class="o">=</span> <span class="mi">102</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span> <span class="o">=</span> <span class="n">vocab_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation&quot;&quot;&quot;</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span><span class="o">.</span><span class="n">merge_dims</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">processed_segments</span><span class="p">,</span> <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">combine_segments</span><span class="p">(</span>
            <span class="p">[</span><span class="n">tokenized</span><span class="p">],</span> <span class="n">MyBertTokenizer</span><span class="o">.</span><span class="n">START_TOKEN</span><span class="p">,</span> <span class="n">MyBertTokenizer</span><span class="o">.</span><span class="n">END_TOKEN</span>
        <span class="p">)</span>
        <span class="n">processed_segments</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">processed_segments</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">segment_ids</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">processed_segments</span><span class="p">,</span> <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">segment_ids</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyBertTokenizer.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation&quot;&quot;&quot;</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span><span class="o">.</span><span class="n">merge_dims</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">processed_segments</span><span class="p">,</span> <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">combine_segments</span><span class="p">(</span>
        <span class="p">[</span><span class="n">tokenized</span><span class="p">],</span> <span class="n">MyBertTokenizer</span><span class="o">.</span><span class="n">START_TOKEN</span><span class="p">,</span> <span class="n">MyBertTokenizer</span><span class="o">.</span><span class="n">END_TOKEN</span>
    <span class="p">)</span>
    <span class="n">processed_segments</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">processed_segments</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">segment_ids</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">processed_segments</span><span class="p">,</span> <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">segment_ids</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.MyBertTokenizerTrimmed" class="doc doc-heading">
            <code>MyBertTokenizerTrimmed</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>BERT Tokenizer with RoundRobinTrimmer.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyBertTokenizerTrimmed.max_seq_len">max_seq_len</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length to which tokenized sequences are trimmed.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyBertTokenizerTrimmed.vocab_file">vocab_file</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Location of BERT vocabulary in filesystem.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyBertTokenizerTrimmed</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;BERT Tokenizer with RoundRobinTrimmer.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        max_seq_len (int): Length to which tokenized sequences are trimmed.</span>
<span class="sd">        vocab_file (str): Location of BERT vocabulary in filesystem.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">START_TOKEN</span> <span class="o">=</span> <span class="mi">101</span>
    <span class="n">END_TOKEN</span> <span class="o">=</span> <span class="mi">102</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span> <span class="o">=</span> <span class="n">max_seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span> <span class="o">=</span> <span class="n">vocab_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmer</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">RoundRobinTrimmer</span><span class="p">(</span><span class="n">max_seq_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span><span class="o">.</span><span class="n">merge_dims</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">trimmed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trimmer</span><span class="o">.</span><span class="n">trim</span><span class="p">([</span><span class="n">tokenized</span><span class="p">])</span>
        <span class="n">processed_segments</span><span class="p">,</span> <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">combine_segments</span><span class="p">(</span>
            <span class="n">trimmed</span><span class="p">,</span>
            <span class="n">MyBertTokenizerTrimmed</span><span class="o">.</span><span class="n">START_TOKEN</span><span class="p">,</span>  <span class="c1"># noqa: E501</span>
            <span class="n">MyBertTokenizerTrimmed</span><span class="o">.</span><span class="n">END_TOKEN</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">processed_segments</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">processed_segments</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">segment_ids</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">processed_segments</span><span class="p">,</span> <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">segment_ids</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;max_seq_len&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyBertTokenizerTrimmed.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span><span class="o">.</span><span class="n">merge_dims</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">trimmed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trimmer</span><span class="o">.</span><span class="n">trim</span><span class="p">([</span><span class="n">tokenized</span><span class="p">])</span>
    <span class="n">processed_segments</span><span class="p">,</span> <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tfText</span><span class="o">.</span><span class="n">combine_segments</span><span class="p">(</span>
        <span class="n">trimmed</span><span class="p">,</span>
        <span class="n">MyBertTokenizerTrimmed</span><span class="o">.</span><span class="n">START_TOKEN</span><span class="p">,</span>  <span class="c1"># noqa: E501</span>
        <span class="n">MyBertTokenizerTrimmed</span><span class="o">.</span><span class="n">END_TOKEN</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">processed_segments</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">processed_segments</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">segment_ids</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">processed_segments</span><span class="p">,</span> <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">segment_ids</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyBertTokenizerTrimmed.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;max_seq_len&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.MyCustomDecoder" class="doc doc-heading">
            <code>MyCustomDecoder</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Collection of decoder blocks arranged in sequence.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.output_dim">output_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of output vector of the Feed Forward NN.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.stack_height">stack_height</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decoder blocks stacked in sequence.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.d_keys">d_keys</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of key vectors in attention layers.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.d_values">d_values</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of value vectors in attention layers.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.h_model">h_model</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads for all Multi Head Attention blocks in the decoder stack.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.dropout_rate">dropout_rate</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic dropout rate used across decoder stack.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoder.decoder_layers">decoder_layers</span></code></td>
            <td>
                  <code>list[<span title="tensorflow.keras.layers.Layer">Layer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Collection of decoder layers in the decoder stack.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyCustomDecoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Collection of decoder blocks arranged in sequence.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        output_dim (int): Length of output vector of the Feed Forward NN.</span>
<span class="sd">        stack_height (int): Number of decoder blocks stacked in sequence.</span>
<span class="sd">        d_keys (int): Length of key vectors in attention layers.</span>
<span class="sd">        d_values (int): Length of value vectors in attention layers.</span>
<span class="sd">        h_model (int): Number of heads for all Multi Head Attention blocks in the decoder stack.</span>
<span class="sd">        dropout_rate (float): Characteristic dropout rate used across decoder stack.</span>
<span class="sd">        decoder_layers (list[tf.keras.layers.Layer]): Collection of decoder layers in the decoder stack.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stack_height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">d_keys</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">d_values</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span> <span class="o">=</span> <span class="n">stack_height</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span> <span class="o">=</span> <span class="n">d_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span> <span class="o">=</span> <span class="n">d_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span> <span class="o">=</span> <span class="n">h_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">MyCustomDecoderLayer</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="k">for</span> <span class="n">decoder_layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">decoder_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
                <span class="s2">&quot;stack_height&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span><span class="p">,</span>
                <span class="s2">&quot;d_keys&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
                <span class="s2">&quot;d_values&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
                <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyCustomDecoder.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span>
    <span class="k">for</span> <span class="n">decoder_layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layers</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">decoder_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyCustomDecoder.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
            <span class="s2">&quot;stack_height&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span><span class="p">,</span>
            <span class="s2">&quot;d_keys&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_keys</span><span class="p">,</span>
            <span class="s2">&quot;d_values&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_values</span><span class="p">,</span>
            <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.MyCustomDecoderLayer" class="doc doc-heading">
            <code>MyCustomDecoderLayer</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Decoder block consisting of a <code>SimpleCausalSelfAttention</code>, <code>SimpleCrossAttention</code>, and <code>FeedForwardNN</code> block in sequence.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.output_dim">output_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of output vector of the Feed Forward NN.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.sa_num_heads">sa_num_heads</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads in <code>SimpleCausalSelfAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ca_num_heads">ca_num_heads</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads in <code>SimpleCrossAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.sa_key_dim">sa_key_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the key tensor in <code>SimpleCausalSelfAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ca_key_dim">ca_key_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the key tensor in <code>SimpleCrossAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.sa_value_dim">sa_value_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the value tensor in <code>SimpleCausalSelfAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ca_value_dim">ca_value_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of the value tensor in <code>SimpleCrossAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ca_dropout_rate">ca_dropout_rate</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout rate in the <code>SimpleCrossAttention</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ff_dropout_rate">ff_dropout_rate</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dropout rate in the <code>FeedForwardNN</code> layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.msa">msa</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Masked Self Attention block.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ca">ca</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Cross Attention block.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomDecoderLayer.ffn">ffn</span></code></td>
            <td>
                  <code><span title="tensorflow.keras.layers.Layer">Layer</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Feed Forward NN block.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyCustomDecoderLayer</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decoder block consisting of a `SimpleCausalSelfAttention`, `SimpleCrossAttention`, and `FeedForwardNN` block in sequence.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        output_dim (int): Length of output vector of the Feed Forward NN.</span>
<span class="sd">        sa_num_heads (int): Number of heads in `SimpleCausalSelfAttention` layer.</span>
<span class="sd">        ca_num_heads (int): Number of heads in `SimpleCrossAttention` layer.</span>
<span class="sd">        sa_key_dim (int): Length of the key tensor in `SimpleCausalSelfAttention` layer.</span>
<span class="sd">        ca_key_dim (int): Length of the key tensor in `SimpleCrossAttention` layer.</span>
<span class="sd">        sa_value_dim (int): Length of the value tensor in `SimpleCausalSelfAttention` layer.</span>
<span class="sd">        ca_value_dim (int): Length of the value tensor in `SimpleCrossAttention` layer.</span>
<span class="sd">        ca_dropout_rate (float: Dropout rate in the `SimpleCrossAttention` layer.</span>
<span class="sd">        ff_dropout_rate (float): Dropout rate in the `FeedForwardNN` layer.</span>
<span class="sd">        msa (tf.keras.layers.Layer): Masked Self Attention block.</span>
<span class="sd">        ca (tf.keras.layers.Layer): Cross Attention block.</span>
<span class="sd">        ffn (tf.keras.layers.Layer): Feed Forward NN block.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sa_num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ca_num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sa_key_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ca_key_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sa_value_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ca_value_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ca_dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">ff_dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sa_num_heads</span> <span class="o">=</span> <span class="n">sa_num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ca_num_heads</span> <span class="o">=</span> <span class="n">ca_num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sa_key_dim</span> <span class="o">=</span> <span class="n">sa_key_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ca_key_dim</span> <span class="o">=</span> <span class="n">ca_key_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sa_value_dim</span> <span class="o">=</span> <span class="n">sa_value_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ca_value_dim</span> <span class="o">=</span> <span class="n">ca_value_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ca_dropout_rate</span> <span class="o">=</span> <span class="n">ca_dropout_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span> <span class="o">=</span> <span class="n">ff_dropout_rate</span>

        <span class="c1"># masked self attention, no dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">msa</span> <span class="o">=</span> <span class="n">SimpleCausalSelfAttention</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sa_num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_key_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_value_dim</span><span class="p">,</span> <span class="mf">0.0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ca</span> <span class="o">=</span> <span class="n">SimpleCrossAttention</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ca_num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_key_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_value_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_dropout_rate</span>
        <span class="p">)</span>  <span class="c1"># cross attention</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForwardNN</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">msa</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>  <span class="c1"># x returned here is dim 203</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
                <span class="s2">&quot;sa_num_heads&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_num_heads</span><span class="p">,</span>
                <span class="s2">&quot;ca_num_heads&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_num_heads</span><span class="p">,</span>
                <span class="s2">&quot;sa_key_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_key_dim</span><span class="p">,</span>
                <span class="s2">&quot;ca_key_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_key_dim</span><span class="p">,</span>
                <span class="s2">&quot;sa_value_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_value_dim</span><span class="p">,</span>
                <span class="s2">&quot;ca_value_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_value_dim</span><span class="p">,</span>
                <span class="s2">&quot;ca_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_dropout_rate</span><span class="p">,</span>
                <span class="s2">&quot;ff_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyCustomDecoderLayer.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">msa</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>  <span class="c1"># x returned here is dim 203</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyCustomDecoderLayer.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
            <span class="s2">&quot;sa_num_heads&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_num_heads</span><span class="p">,</span>
            <span class="s2">&quot;ca_num_heads&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_num_heads</span><span class="p">,</span>
            <span class="s2">&quot;sa_key_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_key_dim</span><span class="p">,</span>
            <span class="s2">&quot;ca_key_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_key_dim</span><span class="p">,</span>
            <span class="s2">&quot;sa_value_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sa_value_dim</span><span class="p">,</span>
            <span class="s2">&quot;ca_value_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_value_dim</span><span class="p">,</span>
            <span class="s2">&quot;ca_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_dropout_rate</span><span class="p">,</span>
            <span class="s2">&quot;ff_dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_dropout_rate</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.MyCustomSimpleDecoder" class="doc doc-heading">
            <code>MyCustomSimpleDecoder</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Collection of decoder blocks arranged in sequence.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomSimpleDecoder.output_dim">output_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of output vector of the Feed Forward NN.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomSimpleDecoder.stack_height">stack_height</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decoder blocks stacked in sequence.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomSimpleDecoder.d_model">d_model</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic vector length used for configuring attention layers.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomSimpleDecoder.h_model">h_model</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of heads for all Multi Head Attention blocks in the decoder stack.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomSimpleDecoder.dropout_rate">dropout_rate</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic dropout rate used across decoder stack.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.MyCustomSimpleDecoder.decoder_layers">decoder_layers</span></code></td>
            <td>
                  <code>list[<span title="tensorflow.keras.layers.Layer">Layer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Collection of decoder layers in the decoder stack.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MyCustomSimpleDecoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Collection of decoder blocks arranged in sequence.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        output_dim (int): Length of output vector of the Feed Forward NN.</span>
<span class="sd">        stack_height (int): Number of decoder blocks stacked in sequence.</span>
<span class="sd">        d_model (int): Characteristic vector length used for configuring attention layers.</span>
<span class="sd">        h_model (int): Number of heads for all Multi Head Attention blocks in the decoder stack.</span>
<span class="sd">        dropout_rate (float): Characteristic dropout rate used across decoder stack.</span>
<span class="sd">        decoder_layers (list[tf.keras.layers.Layer]): Collection of decoder layers in the decoder stack.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stack_height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">h_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span> <span class="o">=</span> <span class="n">stack_height</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span> <span class="o">=</span> <span class="n">h_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">MyCustomDecoderLayer</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
                <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">),</span>
                <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="k">for</span> <span class="n">decoder_layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">decoder_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
                <span class="s2">&quot;stack_height&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span><span class="p">,</span>
                <span class="s2">&quot;d_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
                <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
                <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyCustomSimpleDecoder.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span>
    <span class="k">for</span> <span class="n">decoder_layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layers</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">decoder_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.MyCustomSimpleDecoder.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
            <span class="s2">&quot;stack_height&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_height</span><span class="p">,</span>
            <span class="s2">&quot;d_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
            <span class="s2">&quot;h_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h_model</span><span class="p">,</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.PositionalEncoder" class="doc doc-heading">
            <code>PositionalEncoder</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow.keras.layers.Layer">Layer</span></code></p>


      <p>Positional encoder, as seen in <code>Attention Is All You Need</code></p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="src.modeling.models.custom_layers.PositionalEncoder.output_dim">output_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of resulting positional encoding vector</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PositionalEncoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Positional encoder, as seen in `Attention Is All You Need`</span>

<span class="sd">    Attributes:</span>
<span class="sd">        output_dim (int): Length of resulting positional encoding vector</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes instance based on desired positional encoding vector length</span>

<span class="sd">        Args:</span>
<span class="sd">            output_dim (int): Length of resulting positional encoding vector</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">entry</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">two_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">two_i</span> <span class="o">=</span> <span class="n">two_i</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">base</span> <span class="o">=</span> <span class="mi">10000</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">])</span>
        <span class="n">quotient</span> <span class="o">=</span> <span class="n">entry</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">(</span><span class="n">two_i</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)))</span>
        <span class="n">sin_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">),</span> <span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">cos_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">sin_mask</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">sin_mask</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">quotient</span><span class="p">)</span> <span class="o">+</span> <span class="n">cos_mask</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">quotient</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.PositionalEncoder.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">output_dim</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes instance based on desired positional encoding vector length</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>output_dim</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of resulting positional encoding vector</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes instance based on desired positional encoding vector length</span>

<span class="sd">    Args:</span>
<span class="sd">        output_dim (int): Length of resulting positional encoding vector</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.PositionalEncoder.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">entry</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">two_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">two_i</span> <span class="o">=</span> <span class="n">two_i</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">base</span> <span class="o">=</span> <span class="mi">10000</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">])</span>
    <span class="n">quotient</span> <span class="o">=</span> <span class="n">entry</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">(</span><span class="n">two_i</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)))</span>
    <span class="n">sin_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">),</span> <span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">cos_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">sin_mask</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">sin_mask</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">quotient</span><span class="p">)</span> <span class="o">+</span> <span class="n">cos_mask</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">quotient</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.PositionalEncoder.get_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Updates config object to enable model to be loaded from disk.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates config object to enable model to be loaded from disk.&quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.SimpleCausalSelfAttention" class="doc doc-heading">
            <code>SimpleCausalSelfAttention</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="src.modeling.models.custom_layers.BaseAttention" href="#src.modeling.models.custom_layers.BaseAttention">BaseAttention</a></code></p>


      <p>Special case of <code>BaseAttention</code>. Similar to SimpleSelfAttention, except a causal mask is used in the Multi Head Attention layer, to prevent attention to future tokens.</p>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SimpleCausalSelfAttention</span><span class="p">(</span><span class="n">BaseAttention</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Special case of `BaseAttention`. Similar to SimpleSelfAttention, except a causal mask is used in the Multi Head Attention layer, to prevent attention to future tokens.&quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">use_causal_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.SimpleCausalSelfAttention.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">use_causal_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.SimpleCrossAttention" class="doc doc-heading">
            <code>SimpleCrossAttention</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="src.modeling.models.custom_layers.BaseAttention" href="#src.modeling.models.custom_layers.BaseAttention">BaseAttention</a></code></p>


      <p>Special case of <code>BaseAttention</code> where the value and key are equal, but different from the query. Generally used in encoder-decoder transformers.</p>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SimpleCrossAttention</span><span class="p">(</span><span class="n">BaseAttention</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Special case of `BaseAttention` where the value and key are equal, but different from the query. Generally used in encoder-decoder transformers.&quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.SimpleCrossAttention.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="src.modeling.models.custom_layers.SimpleSelfAttention" class="doc doc-heading">
            <code>SimpleSelfAttention</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="src.modeling.models.custom_layers.BaseAttention" href="#src.modeling.models.custom_layers.BaseAttention">BaseAttention</a></code></p>


      <p>Special case of <code>BaseAttention</code> where the query, value, and key are equal. See <code>BaseAttention</code> for more details.</p>

              <details class="quote">
                <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SimpleSelfAttention</span><span class="p">(</span><span class="n">BaseAttention</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Special case of `BaseAttention` where the query, value, and key are equal. See `BaseAttention` for more details.&quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="src.modeling.models.custom_layers.SimpleSelfAttention.call" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Forward propagation.</p>

            <details class="quote">
              <summary>Source code in <code>src/modeling/models/custom_layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward propagation.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.081f42fc.min.js"></script>
      
    
  </body>
</html>